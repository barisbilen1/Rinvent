[{"path":"https://mkparkin.github.io/Rinvent/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Koray Parkin. Maintainer.","code":""},{"path":"https://mkparkin.github.io/Rinvent/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Koray (2023). Rinvent: Useful simple functions R work cloud, simple functions. R package version 1.0.2, https://github.com/mkparkin/Rinvent/.","code":"@Manual{,   title = {Rinvent: Useful simple functions for R to work with cloud, simple functions},   author = {{Koray}},   year = {2023},   note = {R package version 1.0.2},   url = {https://github.com/mkparkin/Rinvent/}, }"},{"path":[]},{"path":"https://mkparkin.github.io/Rinvent/index.html","id":"intro-page","dir":"","previous_headings":"","what":"Intro Page","title":"Useful simple functions for R to work with cloud, simple functions","text":"https://mkparkin.github.io/Rinvent/","code":""},{"path":"https://mkparkin.github.io/Rinvent/index.html","id":"first-time-install","dir":"","previous_headings":"","what":"First Time Install","title":"Useful simple functions for R to work with cloud, simple functions","text":"","code":"# install.packages(\"devtools\") devtools::install_github(\"mkparkin/Rinvent\",upgrade=\"never\")"},{"path":[]},{"path":"https://mkparkin.github.io/Rinvent/index.html","id":"readparquetr","dir":"","previous_headings":"","what":"readparquetR","title":"Useful simple functions for R to work with cloud, simple functions","text":"Objective read parquet delta files R. Location file can local, aws s3 azure blob useful parameters filter data reading ","code":"# read parquet from local with where condition in the partition readparquetR(pathtoread=\"C:/users/...\", add_part_names=F, sample=F, where=\"sku=1 & store=1\", partition=\"2022\")  #read local delta files readparquetR(pathtoread=\"C:/users/...\", format=\"delta\")  your_connection = AzureStor::storage_container(AzureStor::storage_endpoint(your_link, key=your_key), \"your_container\")  readparquetR(pathtoread=\"blobpath/subdirectory/\", filelocation = \"azure\", format=\"delta\", containerconnection = your_connection)"},{"path":"https://mkparkin.github.io/Rinvent/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Useful simple functions for R to work with cloud, simple functions","text":"Checklist MR clone repo Increase version number DESCRIPTION Add NEWS.md release notes documentation, can use “devtools::document()” Run devtools::build_readme() update README.md pkgdown::build_site() website update","code":""},{"path":[]},{"path":"https://mkparkin.github.io/Rinvent/reference/exampleDataR.html","id":null,"dir":"Reference","previous_headings":"","what":"Sales data for two locations — exampleDataR","title":"Sales data for two locations — exampleDataR","text":"location, item, date level sales data","code":""},{"path":"https://mkparkin.github.io/Rinvent/reference/exampleDataR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sales data for two locations — exampleDataR","text":"","code":"exampleDataR"},{"path":"https://mkparkin.github.io/Rinvent/reference/exampleDataR.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sales data for two locations — exampleDataR","text":"data frame 60 rows 4 columns, 2 location 2 item: location city location, istanbul ankara item sales two items, coffee tea date sales dates. 30 days sales random sales figures 0 40","code":""},{"path":"https://mkparkin.github.io/Rinvent/reference/exampleDataR.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Sales data for two locations — exampleDataR","text":"https://github.com/mkparkin/Rinvent","code":""},{"path":"https://mkparkin.github.io/Rinvent/reference/maR.html","id":null,"dir":"Reference","previous_headings":"","what":"moving average of a column — maR","title":"moving average of a column — maR","text":"moving average column. enough records, take average whatever can. .e. period_cound=5 data 3 values take average three. forget sort data frame. probably based date","code":""},{"path":"https://mkparkin.github.io/Rinvent/reference/maR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"moving average of a column — maR","text":"","code":"maR(value, period_count, timelag = 1, align = \"right\", gap = 1)"},{"path":"https://mkparkin.github.io/Rinvent/reference/maR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"moving average of a column — maR","text":"value column name take average period_count average period count align average past=\"right\" average future=\"left\". default right. gap timelag avg value vs row. .e. want avg one day lag, type gap=1. default 1.","code":""},{"path":"https://mkparkin.github.io/Rinvent/reference/maR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"moving average of a column — maR","text":"","code":"exampleDataR= data.table::as.data.table(exampleDataR) exampleDataR = exampleDataR[order(location,item,date)] exampleDataR[,ma5:= maR(sales,4),list(location,item)] #>     location   item       date sales      ma5 #>  1:   ankara    tea  4/23/1920    22       NA #>  2:   ankara    tea  4/24/1920    30 22.00000 #>  3:   ankara    tea  4/25/1920    29 26.00000 #>  4:   ankara    tea  4/26/1920    34 27.00000 #>  5:   ankara    tea  4/27/1920     9 28.75000 #>  6:   ankara    tea  4/28/1920    15 25.50000 #>  7:   ankara    tea  4/29/1920    40 21.75000 #>  8:   ankara    tea  4/30/1920     7 24.50000 #>  9:   ankara    tea   5/1/1920    26 17.75000 #> 10:   ankara    tea  5/10/1920    39 22.00000 #> 11:   ankara    tea  5/11/1920    39 28.00000 #> 12:   ankara    tea  5/12/1920    12 27.75000 #> 13:   ankara    tea  5/13/1920     2 29.00000 #> 14:   ankara    tea  5/14/1920    29 23.00000 #> 15:   ankara    tea  5/15/1920     7 20.50000 #> 16:   ankara    tea  5/16/1920     0 12.50000 #> 17:   ankara    tea  5/17/1920    35  9.50000 #> 18:   ankara    tea  5/18/1920    34 17.75000 #> 19:   ankara    tea  5/19/1920    20 19.00000 #> 20:   ankara    tea   5/2/1920    25 22.25000 #> 21:   ankara    tea  5/20/1920     2 28.50000 #> 22:   ankara    tea  5/21/1920    30 20.25000 #> 23:   ankara    tea  5/22/1920    30 19.25000 #> 24:   ankara    tea   5/3/1920    30 21.75000 #> 25:   ankara    tea   5/4/1920     0 23.00000 #> 26:   ankara    tea   5/5/1920     1 22.50000 #> 27:   ankara    tea   5/6/1920     4 15.25000 #> 28:   ankara    tea   5/7/1920    35  8.75000 #> 29:   ankara    tea   5/8/1920    20 10.00000 #> 30:   ankara    tea   5/9/1920    28 15.00000 #> 31: istanbul coffee 10/29/1923    27       NA #> 32: istanbul coffee 10/30/1923    31 27.00000 #> 33: istanbul coffee 10/31/1923    31 29.00000 #> 34: istanbul coffee  11/1/1923    22 29.66667 #> 35: istanbul coffee 11/10/1923     6 27.75000 #> 36: istanbul coffee 11/11/1923    37 22.50000 #> 37: istanbul coffee 11/12/1923    22 24.00000 #> 38: istanbul coffee 11/13/1923    32 21.75000 #> 39: istanbul coffee 11/14/1923    25 24.25000 #> 40: istanbul coffee 11/15/1923    22 29.00000 #> 41: istanbul coffee 11/16/1923    20 25.25000 #> 42: istanbul coffee 11/17/1923     3 24.75000 #> 43: istanbul coffee 11/18/1923    39 17.50000 #> 44: istanbul coffee 11/19/1923    26 21.00000 #> 45: istanbul coffee  11/2/1923     3 22.00000 #> 46: istanbul coffee 11/20/1923    21 17.75000 #> 47: istanbul coffee 11/21/1923    27 22.25000 #> 48: istanbul coffee 11/22/1923     1 19.25000 #> 49: istanbul coffee 11/23/1923    10 13.00000 #> 50: istanbul coffee 11/24/1923    33 14.75000 #> 51: istanbul coffee 11/25/1923    23 17.75000 #> 52: istanbul coffee 11/26/1923    28 16.75000 #> 53: istanbul coffee 11/27/1923     6 23.50000 #> 54: istanbul coffee  11/3/1923    28 22.50000 #> 55: istanbul coffee  11/4/1923    30 21.25000 #> 56: istanbul coffee  11/5/1923    30 23.00000 #> 57: istanbul coffee  11/6/1923    35 23.50000 #> 58: istanbul coffee  11/7/1923    32 30.75000 #> 59: istanbul coffee  11/8/1923     2 31.75000 #> 60: istanbul coffee  11/9/1923     9 24.75000 #>     location   item       date sales      ma5 head(exampleDataR,15) #>     location item      date sales   ma5 #>  1:   ankara  tea 4/23/1920    22    NA #>  2:   ankara  tea 4/24/1920    30 22.00 #>  3:   ankara  tea 4/25/1920    29 26.00 #>  4:   ankara  tea 4/26/1920    34 27.00 #>  5:   ankara  tea 4/27/1920     9 28.75 #>  6:   ankara  tea 4/28/1920    15 25.50 #>  7:   ankara  tea 4/29/1920    40 21.75 #>  8:   ankara  tea 4/30/1920     7 24.50 #>  9:   ankara  tea  5/1/1920    26 17.75 #> 10:   ankara  tea 5/10/1920    39 22.00 #> 11:   ankara  tea 5/11/1920    39 28.00 #> 12:   ankara  tea 5/12/1920    12 27.75 #> 13:   ankara  tea 5/13/1920     2 29.00 #> 14:   ankara  tea 5/14/1920    29 23.00 #> 15:   ankara  tea 5/15/1920     7 20.50"},{"path":"https://mkparkin.github.io/Rinvent/reference/readparquetR.html","id":null,"dir":"Reference","previous_headings":"","what":"reading parquet or delta files from local directory or aws s3 or azure blob — readparquetR","title":"reading parquet or delta files from local directory or aws s3 or azure blob — readparquetR","text":"reads parquet,delta files local cloud","code":""},{"path":"https://mkparkin.github.io/Rinvent/reference/readparquetR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"reading parquet or delta files from local directory or aws s3 or azure blob — readparquetR","text":"","code":"readparquetR(   pathtoread,   where = \"\",   partition = \"\",   collist = \"\",   sample = F,   samplesizecount = 3,   add_part_names = F,   format = \"parquet\",   filelocation = \"local\",   containerconnection = NULL,   bucket = NULL )"},{"path":"https://mkparkin.github.io/Rinvent/reference/readparquetR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"reading parquet or delta files from local directory or aws s3 or azure blob — readparquetR","text":"pathtoread reading path, local azure cloud read datatable filter condition. .e. can write =\"column=''\" partition want read partition files pattern. .e. partition=c('2017','2018') collist specific columns read sample sample=T just see sample rows. dont read whole table samplesizecount default=3 rows. can change add_part_names partitioned, need make T add partition names column filelocation \"local\" \"azure\" \"s3\" containerconnection filelocation=\"azure\" need connection name bucket filelocation=\"s3\" need put bucket name","code":""},{"path":"https://mkparkin.github.io/Rinvent/reference/readparquetR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"reading parquet or delta files from local directory or aws s3 or azure blob — readparquetR","text":"","code":"temp <- tempfile() arrow::write_parquet(mtcars, paste(temp,\".parquet\")) readparquetR(paste(temp,\".parquet\")) #>      mpg cyl  disp  hp drat    wt  qsec vs am gear carb #>  1: 21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4 #>  2: 21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4 #>  3: 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1 #>  4: 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1 #>  5: 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2 #>  6: 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1 #>  7: 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4 #>  8: 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2 #>  9: 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2 #> 10: 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4 #> 11: 17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4 #> 12: 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3 #> 13: 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3 #> 14: 15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3 #> 15: 10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4 #> 16: 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4 #> 17: 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4 #> 18: 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1 #> 19: 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2 #> 20: 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1 #> 21: 21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1 #> 22: 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2 #> 23: 15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2 #> 24: 13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4 #> 25: 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2 #> 26: 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1 #> 27: 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2 #> 28: 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2 #> 29: 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4 #> 30: 19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6 #> 31: 15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8 #> 32: 21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2 #>      mpg cyl  disp  hp drat    wt  qsec vs am gear carb readparquetR(pathtoread, collist = c(\"column1\",\"column2\",\"column3\"),format=\"delta\",where=\"SKU==19058901 & STORE!='1905'\") #> Error in list.dirs(pathtoread): object 'pathtoread' not found readparquetR(pathtoread=\"C:/users/...\",add_part_names=F,collist=\"\",sample=F,where=\"sku=1 & store=1\",partition=\"2022\") #> [1] \"C:/users/...\" #> [1] \"there is no row, make sure path is correct!\" #> Null data.table (0 rows and 0 cols) your_connection = AzureStor::storage_container(AzureStor::storage_endpoint(your_link, key=your_key), \"your_container\") #> Error in is_url(url): object 'your_link' not found"}]
